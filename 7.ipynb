{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7c2ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AISHWARYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\AISHWARYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\AISHWARYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AISHWARYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\AISHWARYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AISHWARYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\AISHWARYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text:\n",
      " Natural Language Processing (NLP) enables computers to understand human language. \n",
      "It is widely used in applications like chatbots, sentiment analysis, and machine translation.\n",
      "\n",
      "Tokens:\n",
      " ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'enables', 'computers', 'to', 'understand', 'human', 'language', '.', 'It', 'is', 'widely', 'used', 'in', 'applications', 'like', 'chatbots', ',', 'sentiment', 'analysis', ',', 'and', 'machine', 'translation', '.']\n",
      "\n",
      "POS Tags:\n",
      " [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('enables', 'VBZ'), ('computers', 'NNS'), ('to', 'TO'), ('understand', 'VB'), ('human', 'JJ'), ('language', 'NN'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('widely', 'RB'), ('used', 'VBN'), ('in', 'IN'), ('applications', 'NNS'), ('like', 'IN'), ('chatbots', 'NNS'), (',', ','), ('sentiment', 'NN'), ('analysis', 'NN'), (',', ','), ('and', 'CC'), ('machine', 'NN'), ('translation', 'NN'), ('.', '.')]\n",
      "\n",
      "Tokens after Stopword and Punctuation Removal:\n",
      " ['Natural', 'Language', 'Processing', 'NLP', 'enables', 'computers', 'understand', 'human', 'language', 'widely', 'used', 'applications', 'like', 'chatbots', 'sentiment', 'analysis', 'machine', 'translation']\n",
      "\n",
      "After Stemming:\n",
      " ['natur', 'languag', 'process', 'nlp', 'enabl', 'comput', 'understand', 'human', 'languag', 'wide', 'use', 'applic', 'like', 'chatbot', 'sentiment', 'analysi', 'machin', 'translat']\n",
      "\n",
      "After Lemmatization:\n",
      " ['Natural', 'Language', 'Processing', 'NLP', 'enables', 'computer', 'understand', 'human', 'language', 'widely', 'used', 'application', 'like', 'chatbots', 'sentiment', 'analysis', 'machine', 'translation']\n",
      "\n",
      "After Lemmatization:\n",
      " ['Natural', 'Language', 'Processing', 'NLP', 'enables', 'computer', 'understand', 'human', 'language', 'widely', 'used', 'application', 'like', 'chatbots', 'sentiment', 'analysis', 'machine', 'translation']\n",
      "\n",
      "TF-IDF Matrix (Words vs Documents):\n",
      "\n",
      "   analysis       and  applications  chatbots  computers   enables     human  \\\n",
      "0  0.000000  0.000000      0.000000  0.000000   0.343596  0.343596  0.343596   \n",
      "1  0.323112  0.323112      0.323112  0.323112   0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000      0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "\n",
      "         in        is  language  ...   natural       nlp       of     part  \\\n",
      "0  0.000000  0.000000  0.522627  ...  0.261314  0.000000  0.00000  0.00000   \n",
      "1  0.323112  0.245735  0.000000  ...  0.000000  0.323112  0.00000  0.00000   \n",
      "2  0.000000  0.302674  0.302674  ...  0.302674  0.000000  0.39798  0.39798   \n",
      "\n",
      "   processing  sentiment        to  translation  understand      used  \n",
      "0    0.261314   0.000000  0.343596      0.00000    0.343596  0.000000  \n",
      "1    0.000000   0.323112  0.000000      0.00000    0.000000  0.323112  \n",
      "2    0.302674   0.000000  0.000000      0.39798    0.000000  0.000000  \n",
      "\n",
      "[3 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Install NLTK if not installed\n",
    "# !pip install nltk\n",
    "\n",
    "# Install Scikit-learn if not installed\n",
    "# !pip install scikit-learn\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "# Sample document\n",
    "text = \"\"\"Natural Language Processing (NLP) enables computers to understand human language. \n",
    "It is widely used in applications like chatbots, sentiment analysis, and machine translation.\"\"\"\n",
    "\n",
    "print(\"\\nOriginal Text:\\n\", text)\n",
    "# Tokenize words\n",
    "tokens = word_tokenize(text)\n",
    "print(\"\\nTokens:\\n\", tokens)\n",
    "# Part of Speech Tagging\n",
    "pos_tags = pos_tag(tokens)\n",
    "print(\"\\nPOS Tags:\\n\", pos_tags)\n",
    "# Remove punctuation and stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens_no_stop = [word for word in tokens if word.lower() not in stop_words and word.isalpha()]\n",
    "\n",
    "print(\"\\nTokens after Stopword and Punctuation Removal:\\n\", tokens_no_stop)\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stems = [stemmer.stem(word) for word in tokens_no_stop]\n",
    "\n",
    "print(\"\\nAfter Stemming:\\n\", stems)\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(word) for word in tokens_no_stop]\n",
    "\n",
    "print(\"\\nAfter Lemmatization:\\n\", lemmas)\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(word) for word in tokens_no_stop]\n",
    "\n",
    "print(\"\\nAfter Lemmatization:\\n\", lemmas)\n",
    "# TF-IDF Vectorization\n",
    "documents = [\n",
    "    \"Natural Language Processing enables computers to understand human language.\",\n",
    "    \"NLP is used in applications like chatbots and sentiment analysis.\",\n",
    "    \"Machine translation is a part of Natural Language Processing.\"\n",
    "]\n",
    "\n",
    "# Create TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and Transform\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Show TF-IDF matrix\n",
    "print(\"\\nTF-IDF Matrix (Words vs Documents):\\n\")\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(df_tfidf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
